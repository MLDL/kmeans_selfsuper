{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import zipfile\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "imagenet_path = '/home/vista/Datasets/ILSVRC/Data/CLS-LOC'\n",
    "#imagenet_path = '/home/chaimb/ILSVRC/Data/CLS-LOC'\n",
    "objectnet_path = '/home/chaimb/objectnet-1.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_file(url, filename=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Download file with progressbar\n",
    "\n",
    "    Usage:\n",
    "        download_file('http://web4host.net/5MB.zip')\n",
    "    \"\"\"\n",
    "    if not filename:\n",
    "        local_filename = os.path.join(\".\", url.split('/')[-1])\n",
    "    else:\n",
    "        local_filename = filename\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    with open(filename, \"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content()):\n",
    "            handle.write(data)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "train_dir = pathlib.Path(os.path.join(imagenet_path, 'train'))\n",
    "val_dir = pathlib.Path(os.path.join(imagenet_path, 'val'))\n",
    "object_dir = pathlib.Path(os.path.join(objectnet_path, 'images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert val_dir.exists()\n",
    "assert train_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES_OBJ = np.array([item.name for item in object_dir.glob('*') if item.name != \"LICENSE.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "map_url = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'\n",
    "response = json.loads(requests.get(map_url).text)\n",
    "name_map = {}\n",
    "name_to_num = {}\n",
    "for r in response:\n",
    "    name_map[response[r][0]] = response[r][1]\n",
    "    name_to_num[response[r][1]] = response[r][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5, 5, n + 1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(name_map[CLASS_NAMES[label_batch[n] == 1][0].title().lower()])\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == CLASS_NAMES\n",
    "\n",
    "\n",
    "def get_label_objectnet(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == CLASS_NAMES_OBJ\n",
    "\n",
    "\n",
    "def decode_img(img, IMG_HEIGHT=224, IMG_WIDTH=224, pm1=False):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    if pm1:\n",
    "        img = tf.cast(img, tf.float32) / (255. / 2.) - 1\n",
    "    else:\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    if IMG_HEIGHT == 256:\n",
    "        SIZE = 292\n",
    "    else:\n",
    "        SIZE = 256\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.central_crop(tf.image.resize(img, [SIZE, SIZE]), 0.875)\n",
    "\n",
    "\n",
    "def process_path(file_path, bbg=False, label_function=get_label):\n",
    "    label = label_function(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    if bbg:\n",
    "        img = decode_img(img, 256, 256, True)\n",
    "    else:\n",
    "        img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def prepare_for_eval(ds, batch_size):\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=640)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_datasets(bbg=False):\n",
    "    BATCH_SIZE = 32\n",
    "    process = partial(process_path, bbg=bbg, label_function=get_label)\n",
    "    process_obj = partial(process_path, bbg=bbg, label_function=get_label_objectnet)\n",
    "\n",
    "    list_ds = tf.data.Dataset.list_files(str(train_dir / '*/*'), shuffle=False)\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    labeled_ds = list_ds.map(process, num_parallel_calls=8)\n",
    "\n",
    "    train_ds = prepare_for_eval(labeled_ds, BATCH_SIZE)\n",
    "\n",
    "    list_val_ds = tf.data.Dataset.list_files(str(val_dir / '*/*'), shuffle=False)\n",
    "    # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "    labeled_val_ds = list_val_ds.map(process, num_parallel_calls=8)\n",
    "\n",
    "    val_ds = prepare_for_eval(labeled_val_ds, BATCH_SIZE)\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_resnet50x4_simclr():\n",
    "    resnet50x4_url = \"https://storage.cloud.google.com/simclr-gcs/checkpoints/ResNet50_1x.zip\"\n",
    "\n",
    "    os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "    resnet50x4_path = './checkpoints/checkpoints_ResNet50_4x'\n",
    "    # download_file(resnet50_url,resnet50_path+'.zip')\n",
    "    with zipfile.ZipFile(resnet50x4_path + '.zip', \"r\") as zip_ref:\n",
    "        zip_ref.extractall('./checkpoints')\n",
    "\n",
    "    resnet50x4_path = './checkpoints/ResNet50_4x'\n",
    "    resnet50x4 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(os.path.join(resnet50x4_path, 'hub'))\n",
    "    ])\n",
    "\n",
    "    return resnet50x4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_resnet50_simclr():\n",
    "    resnet50_url = \"https://storage.cloud.google.com/simclr-gcs/checkpoints/ResNet50_1x.zip\"\n",
    "\n",
    "    os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "    resnet50_path = './checkpoints/ResNet50_1x'\n",
    "    # download_file(resnet50_url,resnet50_path+'.zip')\n",
    "    with zipfile.ZipFile(resnet50_path + '.zip', \"r\") as zip_ref:\n",
    "        zip_ref.extractall('./checkpoints')\n",
    "\n",
    "    resnet50 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(os.path.join(resnet50_path, 'hub'))\n",
    "    ])\n",
    "\n",
    "    return resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_resnet152x3_simclrv2():\n",
    "    module_path = 'gs://simclr-checkpoints/simclrv2/pretrained/r152_3x_sk1/hub/'  # r152_3x_sk1\n",
    "    resnet152x3 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_path)\n",
    "    ])\n",
    "    return resnet152x3\n",
    "\n",
    "\n",
    "def get_resnet50_simclrv2():\n",
    "    module_path = 'gs://simclr-checkpoints/simclrv2/pretrained/r50_1x_sk0/hub/'  # r152_3x_sk1\n",
    "    resnet152x3 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_path)\n",
    "    ])\n",
    "    return resnet152x3\n",
    "\n",
    "\n",
    "def get_resnet152_simclrv2():\n",
    "    module_path = 'gs://simclr-checkpoints/simclrv2/pretrained/r152_1x_sk1/hub/'  # r152_3x_sk1\n",
    "    resnet152x3 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_path)\n",
    "    ])\n",
    "    return resnet152x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_revnet50x4_bigbigan():\n",
    "    module_path = 'https://tfhub.dev/deepmind/bigbigan-revnet50x4/1'  # RevNet-50 x4\n",
    "    revnet50x4 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_path, signature='encode')\n",
    "    ])\n",
    "\n",
    "    return revnet50x4\n",
    "\n",
    "\n",
    "def get_resnet50_bigbigan():\n",
    "    module_path = 'https://tfhub.dev/deepmind/bigbigan-resnet50/1'  # ResNet-50\n",
    "    resnet50 = tf.keras.Sequential([\n",
    "        hub.KerasLayer(module_path, signature='encode')\n",
    "    ])\n",
    "\n",
    "    return resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = ['resnet50_simclr', 'resnet50x4_simclr', 'revnet50x4_bigbigan', 'resnet50_simclr2', 'resnet152_simclr2',\n",
    "          'resnet152x3_simclr2']\n",
    "\n",
    "\n",
    "def get_model(model='resnet50_simclr'):\n",
    "    if model == 'resnet50_simclr':\n",
    "        return get_resnet50_simclr()\n",
    "    elif model == 'resnet50x4_simclr':\n",
    "        return get_resnet50x4_simclr()\n",
    "    elif model == 'revnet50x4_bigbigan':\n",
    "        return get_revnet50x4_bigbigan()\n",
    "    elif model == 'resnet50_bigbigan':\n",
    "        return get_resnet50_bigbigan()\n",
    "    elif model == 'resnet50_simclr2':\n",
    "        return get_resnet50_simclrv2()\n",
    "    elif model == 'resnet152_simclr2':\n",
    "        return get_resnet152_simclrv2()\n",
    "    elif model == 'resnet152x3_simclr2':\n",
    "        return get_resnet152x3_simclrv2()\n",
    "    else:\n",
    "        raise ValueError('Wrong model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, ds):\n",
    "    dit = iter(ds)\n",
    "    reses = []\n",
    "    labs = []\n",
    "    num_elements = tf.data.experimental.cardinality(ds).numpy()\n",
    "    for ind in trange(num_elements):\n",
    "        x, y = next(dit)\n",
    "        result = model.predict_on_batch(x)  # , training=False\n",
    "        reses.append(result)\n",
    "        labs.append(y)\n",
    "    rss = np.concatenate(reses, axis=0)\n",
    "    lbs = np.concatenate(labs, axis=0)\n",
    "    return rss, lbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = get_datasets(bbg=False)\n",
    "image_batch, label_batch = next(iter(train_ds))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(train_dir / '*/*'), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(list_ds)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_elements = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "print(num_elements)\n",
    "num_elements = tf.data.experimental.cardinality(val_ds).numpy()\n",
    "print(num_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_and_save(model='resnet50_simclr'):\n",
    "    mdl = get_model(model)\n",
    "    train_embs, train_labs = eval(mdl, train_ds)\n",
    "    val_embs, val_labs = eval(mdl, val_ds)\n",
    "    obj_embs, obj_labs = eval(mdl, obj_ds)\n",
    "    os.makedirs('./results', exist_ok=True)\n",
    "    np.savez(os.path.join('./results', model + '.npz'), train_embs=train_embs, train_labs=train_labs, val_embs=val_embs,\n",
    "             val_labs=val_labs, obj_embs=obj_embs, obj_labs=obj_labs)\n",
    "\n",
    "\n",
    "# eval_and_save(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}